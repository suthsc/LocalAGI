version: '3.8'
services:
  localai:
    # See https://localai.io/basics/container/#standard-container-images for
    # a list of available container images (or build your own with the provided Dockerfile)
    # Available images with CUDA, ROCm, SYCL, Vulkan
    # Image list (quay.io): https://quay.io/repository/go-skynet/local-ai?tab=tags
    # Image list (dockerhub): https://hub.docker.com/r/localai/localai
    # image: localai/localai:master-ffmpeg-core
    image: localai/localai:latest-cpu
    command: 
    - ${MODEL_NAME:-gemma-3-12b-it-qat}
    - ${MULTIMODAL_MODEL:-minicpm-v-2_6}
    - ${IMAGE_MODEL:-sd-1.5-ggml}
    - granite-embedding-107m-multilingual
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/readyz"]
      interval: 60s
      timeout: 10m
      retries: 120
    ports:
    - 8081:8080
    environment:
      - DEBUG=true
      #- LOCALAI_API_KEY=sk-1234567890
    volumes:
      - models:/build/models:cached
      - images:/tmp/generated/images

  localrecall:
    image: quay.io/mudler/localrecall:main
    ports:
      - 8080
    environment:
      - COLLECTION_DB_PATH=/db
      - EMBEDDING_MODEL=granite-embedding-107m-multilingual
      - FILE_ASSETS=/assets
      - OPENAI_API_KEY=sk-1234567890
      - OPENAI_BASE_URL=http://localai:8080
    volumes:
      - localrag-db:/db
      - localrag-assets:/assets

  mcpbox:
    image: suths/mcpbox:latest
    ports:
      - "8080"
    volumes:
      - mcpbox:/app/data
      - /var/run/docker.sock:/var/run/docker.sock
    healthcheck:
      test: ["CMD", "wget", "-q", "-O", "-", "http://localhost:8080/processes"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 2m

  localagi:
    depends_on:
      - localai
      - localrecall
      - mcpbox
    image: localai/localai:latest-cpu
    ports:
      - 8080:3000
    #image: quay.io/mudler/localagi:master
    environment:
      - LOCALAGI_MODEL=${MODEL_NAME:-gemma-3-12b-it-qat}
      - LOCALAGI_MULTIMODAL_MODEL=${MULTIMODAL_MODEL:-minicpm-v-2_6}
      - LOCALAGI_IMAGE_MODEL=${IMAGE_MODEL:-sd-1.5-ggml}
      - LOCALAGI_LLM_API_URL=http://localai:8080
      #- LOCALAGI_LLM_API_KEY=sk-1234567890
      - LOCALAGI_LOCALRAG_URL=http://localrecall:8080
      - LOCALAGI_STATE_DIR=/pool
      - LOCALAGI_TIMEOUT=5m
      - LOCALAGI_ENABLE_CONVERSATIONS_LOGGING=false
      - LOCALAGI_MCPBOX_URL=http://mcpbox:8080
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - localagi:/pool

volumes:
  models:
    driver: local
  images:
    driver: local
  localrag-db:
    driver: local
  localrag-assets:
    driver: local
  mcpbox:
    driver: local
  localagi:
    driver: local